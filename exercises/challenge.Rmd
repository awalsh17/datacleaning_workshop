---
title: "The Data Cleaning Gauntlet"
author: "Alice M Walsh, R-Ladies Philly"
date: "3/28/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introductions

Below I have assembled some data cleaning challenges! The data to clean is all available online. 

*Some of these were originally used August 2018 for an R-Ladies Philadelphia workshop*

In RStudio, you can click a green arrow in the top right corner to run the code chunk. 


# Challenge one - Ingest rectangular data

Philadelphia Farmer's Markets 
dataset sourced from https://www.opendataphilly.org/dataset/farmers-markets-locations/

This first code chunk loads the data using base R `read.csv()`. You should see new variables appear in your Global Environment. 

The goal of challenge one is to just load a comma-separated value (.csv) dataset.

```{r get_data}
data_link <- 'http://data.phl.opendata.arcgis.com/datasets/0707c1f31e2446e881d680b0a5ee54bc_0.csv'
markets_base <- read.csv(data_link)
```


```{r load_packages}
# Do you want to load some packages here? Maybe tidyverse? 
# Here are the packages I loaded to complete the challenges! You made need more or different ones.

library(stringr)
library(tidyverse)
```

## Compare to readr and data.table imports

```{r}
# Add code here to load the same data (data_link) with readr::read_csv

# markets_tidy <- read_csv() ## UNCOMMENT and FINISH THE CODE
```

```{r}
# BONUS: try data.table::fread()

# markets_dt <- data.table::fread() ## UNCOMMENT and FINISH THE CODE
```


# Challenge two - Inspect your data

The first step is to inspect the data. Ask yourself if the data makes sense! Are there values that are impossible, are there missing values, or undesired duplicate values for some columns?


Use two or three commands to look at things like...   

* What is the dimension of the data? 
* What are the variable/column names?
* What data type are the variable/columns?
* How many NA's are there per variable?
* Is the data "tidy"?
* What is different about data imported by read.csv and read_csv??

```{r inspect}
# Put your code here!



# Have you tried?
# skimr::skim()
# dplyr::glimpse()
# str()
# dim()
# colnames()
# DataExplorer::plot_intro() #Note that DataExplorer requires R >= 3.5
```


## Adjust defaults of read.csv(), read_csv()

You will have noticed some differences above... one of the ways to make your life easier when working with a new dataset is to do some of the cleaning when you load the data.

However, it is important that you understand what is happening behind the scenes!

Let's re-import the data with read.csv() and read_csv() using some additional parameters.

```{r reload_data}
# Read some of the documentation
?read.csv
?read_csv

# markets_base <- read.csv(data_link,  # UNCOMMENT AND add here
#                          stringsAsFactors = ,
#                          na.strings = ,
#                          strip.white = ) 

# markets_tidy <- read_csv(data_link, # Add) # UNCOMMENT AND add here
```

#### --- PAUSE HERE ---- ####

# Challenge three - Fix some dirty fields

## Clean a character column

Let's clean up the NEIGHBORHOOD! Use all your favorite commands to look at the values in NEIGHBORHOOD and clean them up. 

For example, "Center City", "Center city", and "Center City " are all different.


```{r clean_neighborhood}
# Create a new data.frame called markets_clean that copies the dirty data
# markets_clean <-  # ADD HERE

# Your code here
# markets_clean$NEIGHBORHOOD <- # add here
```

## Missing values 
What to do with missing values (NAs)? tidyr has a useful function, `replace_na()`

```{r}
?replace_na
# Try out replace_na to replace NAs in ACCEPT_SNAP_ACCESS, ACCEPT_FMNP, ACCEPT_PHILLY_FOOD_BUCKS_ with "N"

# Should these variables be logical instead of character?
```

## Create new variables from existing variable

There are 48 values in the MONTHS variable. It looks like this variable contains information about the dates the farmer's market is open (e.g. "May - October", "Open year round").

The data currently looks like this:

```
  OBJECTID MONTHS                                                                       
1        1 May - September    
2        2 May - October                           
3        3 Tues- June 4th - November 26th; Sat- Year round: 9am - 3pm (May - end of November); 10am - 2…
```

If you wanted to plot the number of farmer's markets that are open by month, how would you do it? Currently, there is too much information in this single MONTHS variable.

Tip: Clean up the MONTHS variable and create some new variables. 

You want something like this:

```
  OBJECTID start_month end_month
1        1         May September
2        2         May   October
3        3     January  December
```
In this example, you have just the months in a standarized format, no dates or other values.

This value, "Wednesdays: June - August, Saturdays: May – October", is particularly painful!

```{r clean_months}
# Add code to process data here
# There are probably hundreds of approaches that could be used
# Try: mutate(), separate(), mutate(), lubridate package, str_to_title()
# Hints: ?month.name, ?month.abb

# If you had cleaner data, you could simply use separate
# Here is an example
easy_data <- tibble(name = c("A","B","C"),
                    months = c("January - December",
                               "February - August",
                               "May - November"))

easy_data %>% 
  separate(col = months, 
           into = c("start_month","end_month"),
           sep = " - ")
```


Bonus: I also decided to create a new data frame that summarized the number of open markets by month.

It will look like this:

```
     month number
1  January      6
2 February      6
3    March      6
4    April      7
5      May     26
```


```{r create_by_month}
# Code to make a new dataset that summarizes the number of open markets by month

# by_month <- #ADD HERE

```

## Bonus: Try the janitor package

The janitor package has some useful functions!
```{r}
library(janitor)
```

Here are some demonstrations on the markets data.
```{r}
markets_base %>% clean_names() %>% names()
```

```{r results='markup'}
# tabyl is cool
markets_base %>% 
  tabyl(NEIGHBORHOOD, ACCEPT_SNAP_ACCESS) %>% 
  adorn_title()
```

#### --- PAUSE HERE ---- ####

# Challenge four - pivot the "old way"

The farmers market and wawa datasets are not great examples to show converting between wide and long data. If you want to practice this, here is an interesting dataset.

* Zillow makes home prices and other data available on their website: https://www.zillow.com/research/data/


```{r load_widedata}
zillow_source <- "http://files.zillowstatic.com/research/public/Zip/Zip_MedianListingPrice_AllHomes.csv"
zillow_wide <- read_csv(zillow_source, col_types = cols())
dim(zillow_wide)
```

The data is 10,000+ rows and 120+ columns. Let's filter to just keep Philadelphia data:

```{r filter_zillow}
# This code uses filter from dplyr package - there are other ways you could do this
zillow_wide <- filter(zillow_wide, City == "Philadelphia")
head(zillow_wide[,c(1,2,7:10)])
```

This data is wide - there are columns for every month with home prices (e.g. "2010-01" and "2016-08"). Instead, we want to have one column with the prices and another with the month and year. How can we convert from wide to long?

This is roughly what I want `zillow_long` to look like:
```{r dummy_df}
fake_zillow_long <- tibble(RegionName = c(19143, 19143, 19143, 19143, 19143),
                               City = c("Philadelphia","Philadelphia","Philadelphia","Philadelphia","Philadelphia"),
                               year = c(2010,2010,2010,2010,2010),
                               month = c(1,2,3,4,5),
                               price = c(79450, 77000, 83500, 79450, 79900))
  
fake_zillow_long
```


```{r reshape_zillow_old}
# Create a new data frame, zillow_long, that contains reshaped data
# Try using the tidyr function, gather()
?gather

# Modify below
# zillow_long <- gather(zillow_wide, 
#                       key = "year-month",
#                       value = "price",
#                       ?) # add selection of columns here!
```

```{r plot_zillow}
# Now we can plot the prices over time for each Philadelphia RegionName (zip code)
# Here is some example code you can modify to fit your dataset or change to make prettier

# ggplot(zillow_long, aes(x = month, y = price, group = RegionName)) + 
#   geom_line() + 
#   facet_wrap(~year)
```

# Challenge five - pivot the "new way"

```{r reshape_zillow_new}
# Create a new data frame, zillow_long, that contains reshaped data
?pivot_longer

# Modify below
# zillow_long <- pivot_longer(zillow_wide, 
#                       cols = , # add here!
#                       names_to = "year-month",
#                       values_to = "price")
```

OK, so now the pivot_wider() function is the opposite!

Let's practice by pivoting zillow_long to a new wide table where each month has it's own column. It will look like this (with some additional columns and rows):

```{r dummy_df_2}
fake_zillow_wide2 <- tibble(RegionName = c(19143, 19143, 19143),
                            City = c("Philadelphia","Philadelphia","Philadelphia"),
                            year = c(2010,2011,2012),
                            price_01 = c(180000, 171400, 164900),
                            price_02 = c(179999, 169450, 165000),
                            price_03 = c(179900, 174900, 165000))
  
fake_zillow_wide2
```

```{r back_to_wide}
# Create a new data frame, zillow_long, that contains reshaped data
?pivot_wider

# Modify below
# zillow_wide_2 <- pivot_wider(zillow_long,
#                       names_from = ,
#                       values_from = ,
#                       names_prefix = )
```

#### --- PAUSE HERE ---- ####

# Challenge six - ingest JSON and make a data.frame

I have previously downloaded data from wawa.com on locations of wawa stores.

To see what JSON looks like, paste: 'https://www.wawa.com/Handlers/LocationByLatLong.ashx?limit=50&lat=39.9526&long=-75.1652' into your web browser.
```{r load_more_packages}
library(jsonlite)
```

```{r}
# This code loads the JSON data
wawa_json <- jsonlite::fromJSON(here::here('exercises','wawa.json'))
# This returns a list with "fuelCategories" "locations"  
class(wawa_json)
```

```{r}
dplyr::glimpse(wawa_json$locations)
```


wawa_json$locations has information on 50 wawa locations. However, you see that this is a nested data frame! amenities, fuelTypes, addresses are not simple list columns.

How can we get this nice and flat!

```{r flatten_json}
# Put your code here
# Try:
# jsonlite::flatten
# tidyr::unnest
# create new data.frames and then rbind, cbind?

# flat_wawa <- #CREATE a flat dataset
```


## Extra challenges

That wawa data is still probably not in a good shape to analyze.  
How would we make it tidy? Is it better to keep it nested?

#### --- PAUSE HERE ---- ####


# Reproducible examples with reprex

https://github.com/tidyverse/reprex

Here are some examples to create a reprex
```{r}
library(reprex)
```


Copy (ctrl+c) the below lines to the clipboard

```{r}
# default is for a github issue
bad_data <- data.frame(money = c(10,20,30,30),
                       name = c("alice","alice","dave","dave"),
                       weekday = c("monday","tuesday","monday","tuesday"))
bad_data
good_data <- tidyr::spread(bad_data, key=name, value=money)
good_data
```

Then run `reprex()`

You can now paste on github or stackoverflow - try it!

You don't want to post a question using data you have loaded, but no one else has.
Hence, creating the dummy `bad_data` data.frame.
Another method is to just use some slice of your real data if it is shareable.

```{r}
# try dput()
dput(iris[1:5,1:5])
```

